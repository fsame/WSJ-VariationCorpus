{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NRQWe8Szp4s"
      },
      "outputs": [],
      "source": [
        "!pip install -qq openai\n",
        "import openai\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "github_token = \"GITHUB TOKEN\"\n",
        "!git clone https://$github_token@github.com/fsame/gpt_humeval.git\n"
      ],
      "metadata": {
        "id": "vBHtM6ZuG2uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gpt_humeval\n"
      ],
      "metadata": {
        "id": "i1owl3ZPMr66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n",
        "!git pull origin main  # or the branch you are working with"
      ],
      "metadata": {
        "id": "kLDHbkDRNtjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"API KEY\""
      ],
      "metadata": {
        "id": "3TcuE03oz4f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_refs(text, helper_sentence):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Generate natural referring expressions for specific referents marked in the text.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "        subject: In the following, you will be presented with a news text from an American newspaper.\n",
        "        The text will talk about one specific subject, which can be, for example, a person, a company, a group, a country or a commercial product.\n",
        "        In the text, all references to one subject are replaced by [REF_number_number] (e.g., REF_1000_1, REF_20_5, etc).\n",
        "        Your goal is to fill those gaps, referring to the main subject of the text, so that the text becomes easy to understand.\n",
        "Always talk about the whole subject: so if the topic is *Mr and Mrs Smith* and you know they are a couple from London, then you can fill a box with \"Mr and Mrs Smith\", \"the London couple\", \"this couple\", \"they\", \"Mr and Mrs Smith's\", \"the couple's\" and so on. But a box is never about \"Mr Smith\" or \"Mrs Smith\" on their own.\n",
        "Although we show you words like \"he\", \"she\", \"it\", \"they\" or similar, you do not have to use them. In the box you can put any way of identifying the subject. If the subject is \"Joe Biden, the president of the United States\" you can put \"Joe Biden\" or \"Mr Biden\" or \"Joe Biden's\" or \"the president of the United States\" or \"the president\" or \"the president's\" or \"him\" or \"his\", or any other way of identifying this person.\n",
        "At the start of each text, you will see a line which gives you the subject of the text (e.g., subject: Margaret Thatcher (she/her)), and the thing or person you need to refer to as you fill out the boxes. To help you understand how to talk about the thing or person you will also have a helper sentence providing more information (e.g., helper sentence: Margaret Thatcher was the prime minister of the United Kingdom.). IMPORTANT POINT: No need to rewrite the whole text. Just write the expressions that are generated as follows:\n",
        "REF_1000_1:\n",
        "REF_20_5:\n",
        "etc.\n",
        ":\\n\n",
        "subject: {subject_line} \\n\n",
        "helper sentence: {helper_sentence} \\n\n",
        "text: {text}\"\"\"}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        #previous model: gpt-3.5-turbo\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Specify the folder containing the .txt files\n",
        "folder_path = \"../gpt_humeval/GPT_experiment/lists/list5\"\n",
        "txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
        "\n",
        "#Open an output file to write the results\n",
        "output_file = open(\"../list5rep19.txt\", \"w\")\n",
        "\n",
        "# Loop through each .txt file and process it\n",
        "for txt_file in txt_files:\n",
        "    file_path = os.path.join(folder_path, txt_file)\n",
        "    with open(file_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    subject_line = lines[0].strip().split(\": \")[1]\n",
        "    helper_sentence = lines[1].strip().split(\": \")[1]\n",
        "\n",
        "\n",
        "    # Concatenate all lines that come after 'text:'\n",
        "    text_start_index = next(i for i, line in enumerate(lines) if line.startswith(\"text:\"))\n",
        "    text = \" \".join(line.strip() for line in lines[text_start_index:]).split(\": \", 1)[1]\n",
        "\n",
        "    # Replace the placeholders in the text\n",
        "    new_text = replace_refs(text, helper_sentence)\n",
        "    #print(new_text)\n",
        "\n",
        "    # Write the results to the output file\n",
        "    output_file.write(new_text + \"\\n\")\n",
        "\n",
        "    # Close the output file\n",
        "output_file.close()"
      ],
      "metadata": {
        "id": "-Bnkh0l1T1jQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}